# In this script we normalize BEA CAINC1 data into our Silver layer

# 1. Set up our Environment
# 2. Read in our Staging Data to R Data Frames
# 3. Standardize our value names
# 4. Union our Data Frames together
# 5. Check for duplicates
# 6. Compute new KPIs and select main columns
# 7. Create Wide and Long versions
# 8. Materialize to Silver

# Find our current directory 
getwd()

# 1. Set up our environment ----
# Read our common libraries & set other packages
source(here::here("scripts", "utils.R"))


# Set paths for our environments
# Make sure we're reading from the project Renviron
if (file.exists(".Renviron")) readRenviron(".Renviron")

# Set our Paths - Pointing to our Bronze folder in Data
bea_key <- get_env_path("BEA_KEY")
data <- get_env_path("DATA")
db_path <- paste0(data, "/duckdb", "/metro_deep_dive.duckdb")

## Connect to the DB ----
con <- dbConnect(duckdb::duckdb(), dbdir = db_path, read_only = FALSE)

# 2. Read in our Staging Data to R Data Frames ----

## Metric Tables ----
county_cainc1_stage <- dbGetQuery(con, "SELECT * FROM staging.bea_regional_county_cainc1")
cbsa_cainc1_stage <- dbGetQuery(con, "SELECT * FROM staging.bea_regional_cbsa_cainc1")
state_cainc1_stage <- dbGetQuery(con, "SELECT * FROM staging.bea_regional_state_cainc1")

## CBSA <> County Xwalk ----
cbsa_county_xwalk <- dbGetQuery(con, "SELECT * FROM silver.xwalk_cbsa_county")

## Reference Tables ----
line_codes_ref <- dbGetQuery(con, "SELECT * FROM silver.bea_regional_metrics_ref")


# 3. Build Final Tables ----
# Column names are already standard and value columns are multiplied

## Define our metrics ----
cainc1_long %>%
  select(code, metric_key, line_desc_clean) %>%
  unique()

## County ----
### Add Line Code Refs to the DF and select base columns ----
county_base <- county_cainc1_stage %>%
  mutate(line_code = as.character(line_code)) %>%
  left_join(line_codes_cainc1,
            by = c("table" = "table", "line_code" = "line_code")) %>%
  select(table, code, geo_level, geo_id, geo_name, 
         period, line_desc_clean, metric_key, value, note_ref)

### De-dupe on the county level & calculate totals kpis ----
county_totals <- county_base %>%
  filter(metric_key %in% c("pi_total", "population")) %>%
  group_by(table, code, geo_level, geo_id, geo_name, 
           period, line_desc_clean, metric_key) %>%
  summarize(value = sum(value, na.rm = TRUE)) %>%
  ungroup()

#### Check for dupes - Good to go ----
county_dupe <- county_totals %>%
  select(code, table, geo_id, period, metric_key) %>%
  group_by(geo_id, period, metric_key) %>%
  summarize(records = n()) %>%
  filter(records > 1)

### Pivot table to wide format to calculate income per capita then reform
county_pc <- county_totals %>%
  select(geo_id, geo_name, geo_level, period, table, metric_key, value) %>%
  pivot_wider(
    names_from  = metric_key,   # pi_total, pi_per_capita, population
    values_from = value
  ) %>%
  mutate(pi_per_capita = pi_total / population) %>%
  mutate(code = "CAINC1-3",
         metric_key = "pi_per_capita",
         line_desc_clean = "Per capita personal income") %>%
  select(table, code, geo_level, geo_id, geo_name, period,
         line_desc_clean, metric_key, value = pi_per_capita)

### Bind Rows to make long data frame ----
county_long <- rbind(
  county_totals,
  county_pc
)


## CBSA ----
### Build CBSA based on our County DFs

### Join Counties to XWalk ----
cbsa_rebase_totals <- county_totals %>%
  dplyr::inner_join(
    cbsa_county_xwalk %>%
      select(county_geoid, county_name, county_flag, 
             cbsa_code, cbsa_name, cbsa_type),
    by = c("geo_id" = "county_geoid")
  )

### Recalculate Totals KPIs ----
cbsa_totals <- cbsa_rebase_totals %>%
  filter(metric_key %in% c("pi_total", "population")) %>%
  group_by(table, code, cbsa_code, cbsa_name, 
           period, line_desc_clean, metric_key) %>%
  summarize(value = sum(value, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(geo_level = "cbsa") %>%
  select(table, code, geo_level, geo_id = cbsa_code, geo_name = cbsa_name,
         period, line_desc_clean, metric_key, value)
 
#### Check for dupes - Good to go ----
cbsa_dupe <- cbsa_totals %>%
  select(code, table, geo_id, period, metric_key) %>%
  group_by(geo_id, period, metric_key) %>%
  summarize(records = n()) %>%
  filter(records > 1)

### Calculate and Reshape Rates ----
cbsa_pc <- cbsa_totals %>%
  select(geo_id, geo_name, geo_level, period, table, metric_key, value) %>%
  pivot_wider(
    names_from  = metric_key,   # pi_total, pi_per_capita, population
    values_from = value
  ) %>%
  mutate(pi_per_capita = pi_total / population) %>%
  mutate(code = "CAINC1-3",
         metric_key = "pi_per_capita",
         line_desc_clean = "Per capita personal income") %>%
  select(table, code, geo_level, geo_id, geo_name, period,
         line_desc_clean, metric_key, value = pi_per_capita)

### Bind Rows to make long data frame ----
cbsa_long <- rbind(
  cbsa_totals,
  cbsa_pc
)

## State
### Join State DF to Line Code Ref, Select final columns
state_base <- state_cainc1_stage %>%
  mutate(line_code = as.character(line_code)) %>%
  left_join(line_codes_cainc1,
            by = c("table" = "table", "line_code" = "line_code")) %>%
select(table, code, geo_level, geo_id, geo_name, 
       period, line_desc_clean, metric_key, value)


## Create Final DFs ----
### Bind Long DFs together ----
long_df <- rbind(
  county_long,
  cbsa_long,
  state_base
)

### Pivot Long DFs wider ----
wide_df <- long_df %>%
  select(geo_level, geo_id, geo_name, period, table, metric_key, value) %>%
  pivot_wider(
    names_from  = metric_key,   # pi_total, pi_per_capita, population
    values_from = value
  )

## Write data frames to our database ----
DBI::dbWriteTable(con, DBI::Id(schema="silver", table="bea_regional_cainc1_long"),
                  long_df, overwrite = TRUE)

DBI::dbWriteTable(con, DBI::Id(schema="silver", table="bea_regional_cainc1_wide"),
                  wide_df, overwrite = TRUE)

# Disconnect our DB ----
dbDisconnect(con, shutdown = TRUE)

## Create Long Data Set ----
# Union together tables, add Line Code Names from 
# Clean up the value names using the Line Code Names from our Ref table

# Union data frames together
cainc1_stage_all <- bind_rows(
  county_cainc1_stage,
  state_cainc1_stage
) %>%
  mutate(line_code = as.character(line_code))

# Keep only CAINC1 from Line Codes
line_codes_cainc1 <- line_codes_ref %>%
  filter(table == "CAINC1") %>%
  select(table, line_code, metric_key, line_desc_clean)

# Join on line_code (and table, if present)
cainc1_long <- cainc1_stage_all %>%
  left_join(line_codes_cainc1,
            by = c("table" = "table", "line_code" = "line_code"))

## Create the Wide data set ----
cainc1_wide <- cainc1_long %>%
  select(geo_level, geo_id, geo_name, period, table, metric_key, value) %>%
  pivot_wider(
    names_from  = metric_key,   # pi_total, pi_per_capita, population
    values_from = value
  )

# Rebase CBSA using County level data ----
# We assume that we have a county level data frame that is already in a long format
# Our crosswalk has a county_geoid and cbsa_code

## Define our metrics ----
cainc1_long %>%
  select(metric_key) %>%
  unique()

# Pi Total, Population, Pi Per Capita

## Use the County DF and Join to CBSA Xwalk to get CBSA ----
cbsa_rebase_base <- cainc1_long %>%
  filter(geo_level == "county") %>%
  dplyr::inner_join(
    cbsa_county_xwalk %>%
      select(county_geoid, county_name, county_flag, 
             cbsa_code, cbsa_name, cbsa_type),
    by = c("geo_id" = "county_geoid")
  )

## Build metrics one by one ----
### Totals KPIs go together in one DF

### Total Income, Population ----
cbsa_totals_kpis <- cbsa_rebase_base %>%
  filter(metric_key %in% c("pi_total", "population")) %>%
  group_by(code, table, cbsa_code, cbsa_name, period, line_code, 
           unit_raw, unit_mult, note_ref, metric_key, line_desc_clean) %>%
  summarize(value_raw = sum(value_raw, na.rm = TRUE),
            value = sum(value, na.rm = TRUE)) %>%
  ungroup()

cbsa_kpi_dupes <- cbsa_totals_kpis %>%
  select(code, table, cbsa_code, cbsa_name, period, metric_key) %>%
  group_by(cbsa_code, period, metric_key) %>%
  summarize(records = n()) %>%
  filter(records > 1)

cbsa_dupe_test <- cbsa_totals_kpis %>% 
  filter(cbsa_code == "10740")

### Income Per Capita ----
cbsa_pc_kpis <- cbsa_totals_kpis %>%
  select(cbsa_code, cbsa_name, period, table, metric_key, value) %>%
  pivot_wider(
    names_from  = metric_key,   # pi_total, pi_per_capita, population
    values_from = value
  ) %>%
  mutate(pi_per_capita = pi_total / population)

## Aggregate our metrics, using correct approaches for different metric types
  ### Only grab the actual grouping variables needed: Code, Table, CBSA, Period, Metric Key
  ### Compute metrics 1 by 1 for base
  ### Compute our per capita metrics later
  ### Put all back together at the end and rebuild the format to match silver


cbsa_rebase_agg <- cbsa_rebase_base %>%
  group_by(code, table, cbsa_code, cbsa_name, period, 
           line_code, unit_mult, note_ref, metric_key, line_desc_clean) %>%
  summarize(
    value = case_when(
      # Income Population
      metric_key == "pi_total" ~ sum(value, na.rm = TRUE),
      # Population
      metric_key == "population" ~ sum(value, na.rm = TRUE),
      TRUE ~ NA_real_            # everything else handled later
    ),
    .groups = "drop"
    
  )

## Compute pi_per_capita based on pi_total and population

## Union together the data frames into one final long data frame


